### 1. 本周完成的工作

- 实验设计与实施：
  
- 数据收集与处理：
- 算法开发与优化：
- 文献阅读：
  - <<A Survey on All-in-One Image Restoration: Taxonomy, Evaluation and Future Trends>>
  - 《Attention Is All You Need》 transformer经典模型，了解transformer的架构与注意力机制
  - Abstract《All-in-One Image Restoration for Unknown Corruption》 airnet模型
- 论文撰写：
  - 

### 2. 遇到的困难和问题

- 技术难点：
- 理论疑惑：自注意力机制及PIR中涉及的transformer block
- 实验问题：
- 其他问题

### 3. 解决方案与已采取的措施

- 问题分析：
- 解决方法：去搜寻了transformer经典论文进行了解
- 寻求的帮助：chatgpt及bilibili相关网课的传授

### 4. 下周工作计划

- 主要目标：了解多模态，深度图估计及多目标优化，同时继续进行基础的巩固
- 具体任务：看动手学习深度学习有关注意力和算法相关的部分，把基础搞明白;将综述里提到的和顺序有关的两篇论文（MiOIR及review learning）阅读完毕
- 时间安排：

### **5. 需要的支持与资源**

- 导师建议：
- 资源需求：

### 6. 其他备注

- 个人心得：
- 目前暂时有了一些大方向，先把相关基础了解清楚，着手开始尝试如何复现，再考虑如何做出改进
