### 周总结模板

### 1. 本周完成的工作

*   实验设计与实施：
*    all in one 领域baseline：airnet复现及RL-restore架构理解
*   数据收集与处理：
*    下载rain100L去雨数据集,BSD400和Urban100去噪数据集
*   算法开发与优化：
*   
*   文献阅读：
    * 《CURL: Contrastive Unsupervised Representations for Reinforcement Learning》将强化学习和无监督表征学习（对比学习）结合来提升采样效率，使得基于pixel也能在相同步数下达到和基于state的方法一样的效果。
    * 《PixelRL: Fully Convolutional Network With Reinforcement Learning for Image Processing》逐像素操作的强化学习框架：1.把每个像素具有一个agent，agent最大化所有像素处的预期总奖励的平均值。2.考虑到智能体数量繁多，采用FCN让所有agent共享参数。3.reward map convolution：将接受到的奖励卷积扩散到领域，使得不仅考虑自身像素的未来状态，而且考虑相邻像素的未来状态。
    * 《REPNP: Plug-and-Play with Deep Reinforcement Learning Prior for Robust Image Restoration》利用轻量级的基于DRL的去噪器进行鲁棒的图像恢复任务，将PnP框架与基于DRL的去噪器相结合，通过随机状态奖励来训练网络。
*   论文撰写：


### 2. 遇到的困难和问题

*   技术难点：

*   理论疑惑：

*   实验问题：1.airnet的训练过程如果不将所有数据集得到会显示无法找到文件，原本考虑先尝试去雨的数据集进行训练，但是去雨的标号txt文件与实际标号不一致且运行过程中会读取其他不存在的数据集报错；2.环境配置问题：在autodl上已经进行了镜像配置，但是在PyCharm中仍显示未安装此包

*   其他问题

### 3. 解决方案与已采取的措施

*   问题分析：1.autodl通过PyCharm无法连接 2.连接过后显示无法找到解释器 
  

*   解决方法：1.连接时去掉前面的root@部分 2.在服务器终端用conda配置虚拟环境

*   寻求的帮助：csdn+chatGPT+autodl官方文档


### 4. 下周工作计划

*   主要目标：列举几个论文中所提到的工具集内容及奖励函数，分解RL-restore，加入airnet中不报错

*   具体任务：1.将airnet和rl-restore的论文对照代码再复习一遍，公式方面要搞清楚 2.确认使用的工具集  3.继续阅读近期的强化学习论文 4.以excel形式整理近期看的强化学习论文的创新点和侧重点

*   时间安排：周五-周一：将两篇论文再复习一遍，理清脉络；同时，分解代码；周二-周四：收集工具集工具，整理近期论文


### **5. 需要的支持与资源**

*   导师建议：梳理清楚rl在图像复原或增强任务中可以执行的action和reward，然后尝试套在不同的baseline上进行优化测试。

*   资源需求：


### 6. 其他备注

*   个人心得：论文和代码要一起进行，同时要及时回顾，公式要理解，要不然还是看不懂。环境配置是复现代码的一个大头，每次配环境都要好几个小时，尽量找readme清晰的开源代码，对于论文选择，也尽量找有开源代码的论文，提升效率。
